{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMYGvw6WbI2LShcVQfRymge"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDylU7at0h5c"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create a dedicated folder for the project\n",
        "import os\n",
        "root_dir = \"/content/drive/MyDrive/MedicalAI_Project\"\n",
        "os.makedirs(root_dir, exist_ok=True)\n",
        "print(f\"Project directory created at: {root_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"monai[nibabel, tqdm]\" einops"
      ],
      "metadata": {
        "id": "6kt9cgN4L22x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from monai.apps import download_and_extract\n",
        "from monai.utils import set_determinism\n",
        "import tarfile\n",
        "\n",
        "set_determinism(seed=42)\n",
        "\n",
        "resource = \"https://msd-for-monai.s3-us-west-2.amazonaws.com/Task01_BrainTumour.tar\"\n",
        "md5 = \"248f43c412504820dc616bc0d79c852d\"\n",
        "\n",
        "# Define the path to the downloaded file\n",
        "compressed_file = os.path.join(root_dir, \"Task01_BrainTumour.tar\")\n",
        "data_dir = os.path.join(root_dir, \"Task01_BrainTumour\")\n",
        "\n",
        "# Manually download and extract\n",
        "if not os.path.exists(data_dir):\n",
        "    print(\"Extracting data...\")\n",
        "    with tarfile.open(compressed_file, 'r') as tar:\n",
        "        tar.extractall(path=root_dir)\n",
        "    print(\"Extraction complete.\")\n",
        "else:\n",
        "    print(\"Data directory already exists.\")"
      ],
      "metadata": {
        "id": "l4TJcZDwMCLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from monai.transforms import (\n",
        "    Compose, LoadImaged, EnsureChannelFirstd, Spacingd,\n",
        "    Orientationd, NormalizeIntensityd, RandSpatialCropd,\n",
        "    RandFlipd, RandScaleIntensityd, RandShiftIntensityd, EnsureTyped\n",
        ")\n",
        "from monai.data import Dataset, DataLoader\n",
        "\n",
        "# 1. Setup Data Lists\n",
        "train_images = sorted(glob.glob(os.path.join(data_dir, \"imagesTr\", \"*.nii.gz\")))\n",
        "train_labels = sorted(glob.glob(os.path.join(data_dir, \"labelsTr\", \"*.nii.gz\")))\n",
        "data_dicts = [{\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(train_images, train_labels)]\n",
        "\n",
        "# 2. Define the Pipeline\n",
        "train_transforms = Compose([\n",
        "    LoadImaged(keys=[\"image\", \"label\"]),\n",
        "    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"), # Standardization\n",
        "    Spacingd(keys=[\"image\", \"label\"], pixdim=(1.0, 1.0, 1.0), mode=(\"bilinear\", \"nearest\")), # Resampling\n",
        "\n",
        "    # Normalization (important for MRIs because brightness varies by machine)\n",
        "    NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
        "\n",
        "    # 3D Data Augmentation\n",
        "    RandSpatialCropd(keys=[\"image\", \"label\"], roi_size=[96, 96, 96], random_size=False),\n",
        "    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
        "    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=1),\n",
        "    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=2),\n",
        "\n",
        "    EnsureTyped(keys=[\"image\", \"label\"]),\n",
        "])\n",
        "\n",
        "# 3. Create Dataset and DataLoader\n",
        "train_ds = Dataset(data=data_dicts, transform=train_transforms)\n",
        "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=2)\n",
        "\n",
        "print(\"Pipeline initialized. Ready to verify first batch.\")"
      ],
      "metadata": {
        "id": "O9pZFYl5PX2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "check_data = next(iter(train_loader))\n",
        "image, label = (check_data[\"image\"][0][0], check_data[\"label\"][0][0])\n",
        "print(f\"Image shape: {image.shape}\") # Should be (96, 96, 96)\n",
        "\n",
        "plt.figure(\"check\", (12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"MRI Slice (Channel 0)\")\n",
        "plt.imshow(image[:, :, 48], cmap=\"gray\")\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Tumor Label\")\n",
        "plt.imshow(label[:, :, 48])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O3-VhSZAPlDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Ensure we are on GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "print(\"Starting Training...\")\n",
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for step, batch_data in enumerate(train_loader):\n",
        "        inputs = batch_data[\"image\"].to(device)\n",
        "        labels_raw = batch_data[\"label\"].to(device)\n",
        "\n",
        "        # Create One-Hot labels and remove the extra dimension\n",
        "        # range(1, 4) because we mapped labels to 1, 2, and 3\n",
        "        labels = torch.stack([labels_raw == i for i in range(1, 4)], dim=1).float()\n",
        "        labels = labels.squeeze(2)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 2. Forward pass (Phase 2: 3D Deep Neural Net)\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # 3. Calculate Dice Loss (Addressing Medical Data Scarcity)\n",
        "        loss = loss_function(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        if (step + 1) % 5 == 0:\n",
        "            print(f\"Epoch {epoch+1}, Step {step+1}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    print(f\"Epoch {epoch+1} Average Loss: {epoch_loss / len(train_loader):.4f}\")\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), os.path.join(root_dir, \"final_brain_model.pth\"))\n",
        "print(\"Model saved.\")"
      ],
      "metadata": {
        "id": "-CK1YZ-2QMlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_code = \"\"\"\n",
        "from fastapi import FastAPI, File, UploadFile\n",
        "import torch\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from monai.networks.nets import AttentionUnet\n",
        "from monai.inferers import sliding_window_inference\n",
        "import io\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# 1. Load the architecture\n",
        "device = torch.device(\"cpu\") # Use CPU for inference stability reasons\n",
        "model = AttentionUnet(\n",
        "    spatial_dims=3,\n",
        "    in_channels=4,\n",
        "    out_channels=3,\n",
        "    channels=(16, 32, 64, 128, 256),\n",
        "    strides=(2, 2, 2, 2),\n",
        ")\n",
        "\n",
        "# 2. Load the trained weights\n",
        "MODEL_PATH = \"final_brain_model.pth\"\n",
        "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "async def predict(file: UploadFile = File(...)):\n",
        "    # Read the uploaded NIfTI file\n",
        "    contents = await file.read()\n",
        "    # In a real app, you'd use nibabel to load this buffer\n",
        "    # and apply the same train_transforms (normalization/RAS)\n",
        "\n",
        "    return {\"status\": \"success\", \"message\": \"3D Volume received and processed.\"}\n",
        "\n",
        "@app.get(\"/\")\n",
        "def health_check():\n",
        "    return {\"status\": \"online\", \"model\": \"AttentionUnet-3D-BraTS\"}\n",
        "\"\"\"\n",
        "\n",
        "with open(os.path.join(root_dir, \"main.py\"), \"w\") as f:\n",
        "    f.write(api_code)\n",
        "\n",
        "print(\"FastAPI script 'main.py' has been created in your project folder.\")"
      ],
      "metadata": {
        "id": "C34PyCy2YYwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docker_code = \"\"\"\n",
        "FROM python:3.9-slim\n",
        "\n",
        "WORKDIR /app\n",
        "\n",
        "# Install system dependencies for medical imaging\n",
        "RUN apt-get update && apt-get install -y libgl1-mesa-glx && rm -rf /var/lib/apt/lists/*\n",
        "\n",
        "COPY requirements.txt .\n",
        "RUN pip install --no-cache-dir -r requirements.txt\n",
        "\n",
        "COPY . .\n",
        "\n",
        "# Expose the port FastAPI runs on\n",
        "EXPOSE 8000\n",
        "\n",
        "CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
        "\"\"\"\n",
        "\n",
        "with open(os.path.join(root_dir, \"Dockerfile\"), \"w\") as f:\n",
        "    f.write(docker_code)\n",
        "\n",
        "# Create a requirements file for the container\n",
        "with open(os.path.join(root_dir, \"requirements.txt\"), \"w\") as f:\n",
        "    f.write(\"torch\\\\nmonai\\\\nnibabel\\\\nfastapi\\\\nuvicorn\\\\npython-multipart\\\\nnumpy\")\n",
        "\n",
        "print(\"Dockerfile and requirements.txt created.\")"
      ],
      "metadata": {
        "id": "rzlPcDbCYrdC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}